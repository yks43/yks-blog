>   官网译：
>
>   Redis是一个开源的，**基于内存的数据结构存储**，可用作于数据库、**缓存**、消息中间件。

*   官方角度：Redis是基于内存，支持多种数据结构
*   经验角度：Redis常被用作缓存

## 使用场景



*   高性能：假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可

*   高并发：直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。

*   用作分布式锁，Redis的部分操作是原子性的，多个节点可选用Redis做分布式锁

    

## 数据结构

>   "Redis is written in ANSI C"

Redis支持丰富的数据结构，**常用**的有string、list、hash、set、sortset这几种



tips：Redis存储是以key-value形式存储的，key一定是字符串，value便是支持的数据结构



注意一下：Redis并没有直接使用这些数据结构来构建key-value数据库，而是基于这些数据结构创建了一个对象系统

>   Redis使用对象表示数据库中的键和值，所以每次新建一个kv时，便会创建两个对象（键对象+值对象）

每一个对象都由一个redisObject结构表示

```c
typedef struct redisObject{

    // 对象的类型
    unsigned type 4:;

    // 对象的编码格式
    unsigned encoding:4;

    // 指向底层实现数据结构的指针
    void * ptr;

    //.....

}robj;
```

| 类型         | 编码                      | 对象                                           |
| ------------ | ------------------------- | ---------------------------------------------- |
| REDIS_STRING | REDIS_ENCODING_INT        | 使用整数值实现的字符串对象                     |
| REDIS_STRING | REDIS_ENCODING_EMBSTR     | 使用embstr编码的简单动态字符串实现的字符串对象 |
| REDIS_STRING | REDIS_ENCODING_RAW        | 使用简单动态字符串实现的字符串对象             |
| REDIS_LIST   | REDIS_ENCODING_ZIPLIST    | 使用压缩列表实现的列表对象                     |
| REDIS_LIST   | REDIS_ENCODING_LINKEDLIST | 使用双端链表实现的列表对象                     |
| REDIS_HASH   | REDIS_ENCODING_ZIPLIST    | 使用压缩列表实现的哈希对象                     |
| REDIS_HASH   | REDIS_ENCODING_HT         | 使用字典实现的哈希对象                         |
| REDIS_SET    | REDIS_ENCODING_INTSET     | 使用整数集合实现的集合对象                     |
| REDIS_SET    | REDIS_ENCODING_HT         | 使用字典实现的集合对象                         |
| REDIS_ZSET   | REDIS_ENCODING_ZIPLIST    | 使用压缩列表实现的有序集合对象                 |
| REDIS_ZSET   | REDIS_ENCODING_SKIPLIST   | 使用跳跃表和字典实现的有序集合对象             |

Redis对`key-value`封装成对象，key是一个对象，value也是一个对象。每个对象都有type(类型)、encoding(编码)、ptr(指向底层数据结构的指针)来表示。



### SDS简单动态字符串(string)

Redis中的字符串不同于C语言中的字符串

Redis使用sdshdr结构来表示一个SDS值：

```c
struct sdshdr {
    // 字节数组，用于保存字符串
    char buf[];

    // 记录buf数组中已使用的字节数量，也是字符串的长度
    int len;

    // 记录buf数组未使用的字节数量
    int free;
}
```

#### 使用SDS的原因

*   sdshdr数据结构中用len属性记录了字符串的长度。那么**获取字符串的长度时，时间复杂度只需要O(1)**。
*   SDS不会发生溢出的问题，如果修改SDS时，空间不足。先会扩展空间，再进行修改！(**内部实现了动态扩展机制**)。
*   SDS可以**减少内存分配的次数**(空间预分配机制)。在扩展空间时，除了分配修改时所必要的空间，还会分配额外的空闲空间(free 属性)。
*   SDS是**二进制安全的**，所有SDS API都会以处理二进制的方式来处理SDS存放在buf数组里的数据。

#### C字符串与SDS之间的区别

| C字符串                                  | SDS                                |
| ---------------------------------------- | ---------------------------------- |
| 获取字符串长度的复杂度为O(N)             | 获取字符串长度的复杂度为O(1)       |
| API是不安全的，可能会造成缓存区溢出      | API是安全的，不会造成缓存区溢出    |
| 修改字符串长度N次必然要执行N次内存重分配 | 修改字符串N次最多执行N次内存分配   |
| 只能保存文本数据                         | 可以保存文本数据或者二进制数据     |
| 可以使用所有格<string,h>库中的函数       | 可以使用一部分<string.h>库中的函数 |

>   这些区别主要在于SDS针对于这些问题的数据结构优化，
>
>   C字符串本身的缺陷；例如：只能遍历获取len，遇空判断结束...
>
>   sdshdr.len   sdshdr.free

#### SDS API

很多，有需要直接查

### 链表(list)

Redis构建了自己的链表实现，

Redis中链表的应用：

*   列表键的底层实现之一，当一个列表键包含了数量比较多的元素， 又或者列表中包含的元素都是比较长的字符串时， Redis就会使用链表作为列表键的底层实现。  
*   发布与订阅、 慢查询、 监视器等功能也用到了链表， Redis服务器本身
    还使用链表来保存多个客户端的状态信息， 以及使用链表来构建客户端输出缓冲区（output
    buffer）  

Redis中链表的代码实现：

每个链表节点使用adlist.h/listNode结构来表示

```c
typedef strcut listNode{
    //前置节点
    strcut listNode  *pre;
    //后置节点
    strcut listNode  *pre;
    //节点的值
    void  *value;
}listNode
```

多个listNode可以通过prev和next指针组成双端链表  

虽然仅仅使用多个listNode结构就可以组成链表， 但使用adlist.h/list来持有链表的话， 操
作起来会更方便：  

```c
ypedef struct list{
    //表头结点
    listNode  *head;
    //表尾节点
    listNode  *tail;
    //链表长度
    unsigned long len;
    //节点值复制函数
    void *(*dup) (viod *ptr);
    //节点值释放函数
    void  (*free) (viod *ptr);
    //节点值对比函数
    int (*match) (void *ptr,void *key);
}list
```

链表特性：

*   双端：链表节点带有prev和next指针， 获取某个节点的前置节点和后置节点的复杂度都
    是O（1） 。  
*   无环：表头节点的prev指针和表尾节点的next指针都指向NULL， 对链表的访问以
    NULL为终点。  
*   带表头指针和表尾指针： 通过list结构的head指针和tail指针， 程序获取链表的表头节点
    和表尾节点的复杂度为O（1） 。  
*   带链表长度计数器： 程序使用list结构的len属性来对list持有的链表节点进行计数， 程序
    获取链表中节点数量的复杂度为O（1） 。  
*   多态： 链表节点使用void*指针来保存节点值， 并且可以通过list结构的dup、 free、
    match三个属性为节点值设置类型特定函数， 所以链表可以用于保存各种不同类型的值。  

#### 链表 API

>   需要时直接看文档即可

### 哈希表（字典）

Redis中哈希表的实现：

>   Redis的字典使用哈希表作为底层实现， 一个哈希表里面可以有多个哈希表节点， 而每个
>   哈希表节点就保存了字典中的一个键值对。  

哈希表	dict.h/dictht

```c
typedef struct dictht{
        //哈希表数组
        dictEntry **table;  
        //哈希表大小
        unsigned long size;    
        //哈希表大小掩码，用于计算索引值
        //总是等于size-1
        unsigned long sizemark;     
        //哈希表已有节点数量
        unsigned long used;
    }dictht
```

table属性是一个数组， 数组中的每个元素都是一个指向dict.h/dictEntry结构的指针， 每个
dictEntry结构保存着一个键值对。 size属性记录了哈希表的大小， 也即是table数组的大小， 而
used属性则记录了哈希表目前已有节点（键值对） 的数量。 sizemask属性的值总是等于size-
1， 这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。



哈希表节点：

```c
 typedef struct dictEntry {
        //键
        void *key;
        //值
        union {
            void *value;
            uint64_tu64;
            int64_ts64;
        }v;    
        //指向下个哈希节点，组成链表
        struct dictEntry *next;
    }dictEntry;
```

key属性保存着键值对中的键， 而v属性则保存着键值对中的值， 其中键值对的值可以是
一个指针， 或者是一个uint64_t整数， 又或者是一个int64_t整数。
next属性是指向另一个哈希表节点的指针， 这个指针可以将多个哈希值相同的键值对连
接在一次， 以此来解决键冲突（collision） 的问题。  



Redis为了更好操作，对哈希表又封装了一层

```c
typedef struct dict {
    //类型特定函数
    dictType *type;
    //私有数据
    void *privdata;
    //哈希表
    dictht ht[2];
    //rehash索引
    //当rehash不进行时，值为-1
    int rehashidx;  
}dict;

//-----------------------------------

typedef struct dictType{
    //计算哈希值的函数
    unsigned int (*hashFunction)(const void * key);
    //复制键的函数
    void *(*keyDup)(void *private, const void *key);
    //复制值得函数
    void *(*valDup)(void *private, const void *obj);  
    //对比键的函数
    int (*keyCompare)(void *privdata , const void *key1, const void *key2)
    //销毁键的函数
    void (*keyDestructor)(void *private, void *key);
    //销毁值的函数
    void (*valDestructor)(void *private, void *obj);  
}dictType
```

type属性和privdata属性是针对不同类型的键值对， 为创建多态字典而设置的：
type属性是一个指向dictType结构的指针， 每个dictType结构保存了一簇用于操作特定
类型键值对的函数， Redis会为用途不同的字典设置不同的类型特定函数。
而privdata属性则保存了需要传给那些类型特定函数的可选参数。  



Redis中有两个哈希表

*   ht[0]：用于存放**真实**的`key-vlaue`数据
*   ht[1]：用于**扩容(rehash)**

Redis中的哈希冲突与HashMap的区别

-   Redis哈希冲突时：将新节点添加在链表的**表头**。
-   JDK1.8后，Java在哈希冲突时：是将新的节点添加到链表的**表尾**。

#### 哈希函数

当要将一个新的键值对添加到字典里面时， 程序需要先根据键值对的键计算出哈希值和
索引值， 然后再根据索引值， 将包含新键值对的哈希表节点放到哈希表数组的指定索引上
面。
Redis计算哈希值和索引值的方法如下：  

```c
#使用字典设置的哈希函数， 计算键key的哈希值
hash = dict->type->hashFunction(key);
#使用哈希表的sizemask属性和哈希值， 计算出索引值
#根据情况不同， ht[x]
可以是ht[0]
或者ht[1]
index = hash & dict->ht[x].sizemask;
```

#### rehash过程

Redis专门准备了一个哈希表（ht[1]）用于rehash，rehash采用**渐进式**完成

采用渐进式的原因：**数据量如果过大的话，一次性rehash会有庞大的计算量，这很可能导致服务器一段时间内停止服务**。

##### 大小：

扩容：used*2(2的n次方)

收缩：used(2的n次方)

##### 触发条件：

当以下条件中的任意一个被满足时， 程序会自动开始对哈希表执行扩展操作 ：

*   服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令， 并且哈希表的负载
    因子大于等于1。  
*   服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令， 并且哈希表的负载因
    子大于等于5。  

根据BGSAVE命令或BGREWRITEAOF命令是否正在执行， 服务器执行扩展操作所需的
负载因子并不相同， 这是因为在执行BGSAVE命令或BGREWRITEAOF命令的过程中， Redis
需要创建当前服务器进程的子进程， 而大多数操作系统都采用写时复制（copy-on-write） 技
术来优化子进程的使用效率， 所以在子进程存在期间， 服务器会提高执行扩展操作所需的负
载因子， 从而尽可能地避免在子进程存在期间进行哈希表扩展操作， 这可以避免不必要的内
存写入操作， 最大限度地节约内存。
另一方面， 当哈希表的负载因子小于0.1时， 程序自动开始对哈希表执行收缩操作。  

>   负载因子计算：
>
>   负载因子=哈希表已保存节点数量/哈希表大小
>   load_factor = ht[0].used / ht[0].size  



1.  在字典中维持一个索引计数器变量rehashidx，并将设置为0，表示rehash开始。
2.  在rehash期间每次对字典进行增加、查询、删除和更新操作时，**除了执行指定命令外**；还会将ht[0]中rehashidx索引上的值**rehash到ht[1]**，操作完成后rehashidx+1。
3.  字典操作不断执行，最终在某个时间点，所有的键值对完成rehash，这时**将rehashidx设置为-1，表示rehash完成**
4.  在渐进式rehash过程中，字典会同时使用两个哈希表ht[0]和ht[1]，所有的更新、删除、查找操作也会在两个哈希表进行。例如要查找一个键的话，**服务器会优先****查找ht[0]，如果不存在，再查找ht[1]**，诸如此类。此外当执行**新增操作**时，新的键值对**一律保存到ht[1]**，不再对ht[0]进行任何操作，以保证ht[0]的键值对数量只减不增，直至变为空表。



### 跳跃表（skiplist)

>   跳跃表（skiplist） 是一种有序数据结构， 它通过在每个节点中维持多个指向其他节点的
>   指针， 从而达到快速访问节点的目的。
>   跳跃表支持平均O（logN） 、 最坏O（N） 复杂度的节点查找， 还可以通过顺序性操作来
>   批量处理节点。  

使用的地方：

*   实现有序集合键
*   在集群节点中用作内部数据结构

#### 实现

Redis的跳跃表由redis.h/zskiplistNode和redis.h/zskiplist两个结构定义， 其中zskiplistNode结
构用于表示跳跃表节点， 而zskiplist结构则用于保存跳跃表节点的相关信息， 比如节点的数
量， 以及指向表头节点和表尾节点的指针等等。  

![](D:\my_files\desktop\yonghui\md\images\跳跃表.jpg)

zskiplistNode:

*   header： 指向跳跃表的表头节点。
*   tail： 指向跳跃表的表尾节点。
*   level： 记录目前跳跃表内， 层数最大的那个节点的层数（表头节点的层数不计算在内） 。
*   length： 记录跳跃表的长度， 也即是， 跳跃表目前包含节点的数量（表头节点不计算在内） 。  

zskiplistzNode

*   层（level）：节点中用L1、 L2、 L3等字样标记节点的各个层， L1代表第一层， L2代表
    第二层， 以此类推。 每个层都带有两个属性： 前进指针和跨度。 前进指针用于访问位于表尾
    方向的其他节点， 而跨度则记录了前进指针所指向节点和当前节点的距离。 在上面的图片
    中， 连线上带有数字的箭头就代表前进指针， 而那个数字就是跨度。 当程序从表头向表尾进
    行遍历时， 访问会沿着层的前进指针进行。  

*   后退指针（backward）：节点中用BW字样标记节点的后退指针， 它指向位于当前节点
    的前一个节点。 后退指针在程序从表尾向表头遍历时使用。  
*   分值（score）：各个节点中的1.0、2.0、3.0是节点所保存的分值。 在跳跃表中， 节点按
    各自所保存的分值从小到大排列  
*   成员对象（obj）：各个节点中的o1、 o2和o3是节点所保存的成员对象。  

注意表头节点和其他节点的构造是一样的： 表头节点也有后退指针、 分值和成员对象，
不过表头节点的这些属性都不会被用到， 所以图中省略了这些部分， 只显示了表头节点的各
个层。  

#### 重点：

*   每个跳跃表节点的层高都是1至32之间的随机数。  
*   在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。
*   跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行
    排序。    

### 整数集合(intset)

整数集合（intset） 是集合键的底层实现之一， 当一个集合只包含整数值元素， 并且这个集合的元素数量不多时， Redis就会使用整数集合作为集合键的底层实现。  

#### 实现

```c
typedef struct intset {
//编码方式
uint32_t encoding;
//集合包含的元素数量
uint32_t length;
//保存元素的数组
int8_t contents[];
} intset;
```

*   contents数组是整数集合的底层实现： 整数集合的每个元素都是contents数组的一个数组项（item）， 各个项在数组中按值的大小从小到大有序地排列， 并且数组中不包含任何重复项  
*   虽然intset结构将contents属性声明为int8_t类型的数组， 但实际上contents数组并不保存任何int8_t类型的值， contents数组的真正类型取决于encoding属性的值  

#### 升级

每当我们要将一个新元素添加到整数集合里面， 并且新元素的类型比整数集合现有所有元素的类型都要长时， 整数集合需要先进行升级（upgrade） ， 然后才能将新元素添加到整数集合里面

升级整数集合并添加新元素共分为三步进行 :

1.  根据新元素的类型， 扩展整数集合底层数组的空间大小， 并为新元素分配空间。  
2.  将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。  
3.  将新元素添加到底层数组里面  

因为每次向整数集合添加新元素都可能会引起升级， 而每次升级都需要对底层数组中已有的所有元素进行类型转换， 所以向整数集合添加新元素的时间复杂度为O（N） 。  

##### 好处：

*   提高灵活度
*   节约内存

##### 降级

整数集合不支持降级操作， 一旦对数组进行了升级， 编码就会一直保持升级后的状态。  

### 压缩链表(ziplist)

>   压缩列表（ziplist） 是列表键和哈希键的底层实现之一。 当一个列表键只包含少量列表
>   项， 并且每个列表项要么就是小整数值， 要么就是长度比较短的字符串， 那么Redis就会使用
>   压缩列表来做列表键的底层实现。  

##### 实现

压缩列表是Redis为了节约内存而开发的， 是由一系列特殊编码的连续内存块组成的顺序
型（sequential） 数据结构。 一个压缩列表可以包含任意多个节点（entry） ， 每个节点可以保
存一个字节数组或者一个整数值。  

*   zlbytes：uint32_t，用于记录整个压缩列表占用的内存字节数，在对压缩列表进行内存重分配，或者计算zlend的位置使用
*   zltail：uint32_t，用于记录压缩列表表尾节点举例压缩列表的起始地址有多少字节，通过这个偏移量，程序无需遍历整个压缩列表就可以确定表尾节点的地址
*   zllen：uint16_t，记录了压缩链表包含的节点数量，当这个属性的值小于uint16_MAX(65535)时，这个属性的值就是压缩列表包含节点的数量；当这个值等于uint16_MAX时，节点的真实数量需要遍历整个压缩列表才能计算得出
*   entryX：列表节点，节点长度由节点保存的内容确定
*   zlend：uint8_t，特殊值OxFF(十进制255)，用于标记压缩列表的末端

entryX：

*   previous_entry_length：记录前一个节点的长度，1字节/5字节，程序可以通过指针运算，根据当前节点的起始地址来计算出前一个节点的起始位置
*   encoding：记录content数据的类型和长度
*   content：节点的值

##### 连锁更新

>   特殊情况下的增删（几率很小），造成previous_entry_length无法适配，重新变更大小

## 对象

>   Redis并没有直接使用数据结构来实现键值对数据库，而是基于这些数据结构构建了一个对象系统

#### 对象类型和编码

Redis使用对象来表示数据库中的键和值，在Redis中新建一个键值对时，至少创建了两个对象（键对象+值对象）

Redis中每个对象都由一个redisObject结构表示

```c
typedef struct redisObject {
//类型
unsigned type:4;
//编码
unsigned encoding:4;
//指向底层实现数据结构的指针
void *ptr;
// ...
} robj;
```

*   type：REDIS_STRING,REDIS_LIST,REDIS_HASH,REDIS_SET,REDIS_ZSET
*   encoding：标识使用的编码/数据结构，每种类型的对象都至少使用了两种不同的编码（灵活性和效率，根据不同的场景为一个对象设置不同的编码，从而优化对象在某一场景下的效率）

#### 字符串对象

##### 编码

int，raw，embstr

##### 编码转换

##### api

*   set
*   get
*   append
*   incrbyfloat
*   incrby
*   decrby
*   strlen
*   setrange
*   getrange

#### 列表对象

##### 编码

*   ziplist

*   linkedlist

##### 编码转换

*   使用ziplist的条件，同时满足时即可（可通过配置文件更改）:
    *   列表对象保存的所有字符串元素的长度都小于64字节  
    *   列表对象保存的元素数量小于512个； 不能满足这两个条件的列表对象需要使用linkedlist
        编码。  

##### api



#### 哈希对象

##### 编码

*   ziplist
*   hashtable

##### 编码转换

*   ziplist（同时满足）
    *   哈希对象保存的所有键值对的键和值的字符串长度都小于64字节；  
    *   哈希对象保存的键值对数量小于512个； 不能满足这两个条件的哈希对象需要使用
        hashtable编码。

##### api

#### 集合对象

##### 编码

*   intset
*   hashtable

##### 编码转换

*   intset
    *   集合对象保存的所有元素都是整数值；  
    *   集合对象保存的元素数量不超过512个。  

##### api



#### 有序集合对象

##### 编码

*   ziplist
*   skiplist(zset(dict，zskiplist))

##### 编码转换

*   ziplist（同时满足）
    *   有序集合保存的元素数量小于128个；  
    *   有序集合保存的所有元素成员的长度都小于64字节；  

##### api



### 内存回收

>   因为C语言并不具备自动内存回收功能， 所以Redis在自己的对象系统中构建了一个引用
>   计数（reference counting） 技术实现的内存回收机制， 通过这一机制， 程序可以通过跟踪对
>   象的引用计数信息， 在适当的时候自动释放对象并进行内存回收。  

每个对象的引用计数信息由redisObject结构的refcount属性记录  

*   在创建一个新对象时， 引用计数的值会被初始化为1；  
*   当对象被一个新程序使用时， 它的引用计数值会被增一；  
*   当对象不再被一个程序使用时， 它的引用计数值会被减一；  
*   当对象的引用计数值变为0时， 对象所占用的内存会被释放。  

### 对象共享

>   除了用于实现引用计数内存回收机制之外， 对象的引用计数属性还带有对象共享的作
>   用。  保存整数值的值对象，其他类型的值对象验证是否完全相同所需的复杂度过高

在Redis中， 让多个键共享同一个值对象需要执行以下两个步骤：

1.  将数据库键的值指针指向一个现有的值对象；
2.  被共享的值对象的引用计数增一。  

### 空转时长

redisObject的lru属性，该属性记录了对象最后一次被命令程序访问的时间，可通过OBJECT IDLETIME命令打印空转时长，当前时间-lru时间

tips：如果服务器打开了maxmemory选项， 并且服务器用于回收内存的算法为volatile-lru或者
allkeys-lru， 那么当服务器占用的内存数超过了maxmemory选项所设置的上限值时， 空转时
长较高的那部分键会优先被服务器释放， 从而回收内存。  

## 数据库

### 初始化

Redis服务器将所有数据库都保存在服务器状态redis.h/redisServer结构的db数组中， db数组的每个项都是一个redis.h/redisDb结构， 每个redisDb结构代表一个数据库；在初始化服务器时， 程序会根据服务器状态的dbnum属性来决定应该创建多少个数据库；dbnum属性的值由服务器配置的database选项决定， 默认情况下，该选项的值为16，所以Redis服务器默认会创建16个数据库；

```c
struct redisServer {
// ...
//一个数组， 保存着服务器中的所有数据库
redisDb *db;
//服务器中数据库的数量
int dbnum;
// ...
};
```

### 切换数据库

每个Redis客户端都有自己的目标数据库， 每当客户端执行数据库写命令或者数据库读命
令的时候， 目标数据库就会成为这些命令的操作对象。
默认情况下， Redis客户端的目标数据库为0号数据库， 但客户端可以通过执行SELECT命
令来切换目标数据库。  

```c
typedef struct redisClient {
// ...
//记录客户端当前正在使用的数据库
redisDb *db;
// ...
} redisClient;
```

redisClient.db指针指向redisServer.db数组的其中一个元素， 而被指向的元素就是客户端
的目标数据库。  

### 键空间

Redis是一个键值对（key-value pair） 数据库服务器， 服务器中的每个数据库都由一个
redis.h/redisDb结构表示， 其中， redisDb结构的dict字典保存了数据库中的所有键值对， 我们
将这个字典称为键空间（key space） ：  

```c
typedef struct redisDb {
// ...
//数据库键空间， 保存着数据库中的所有键值对
dict *dict;
// ...
} redisDb;
```

*   键空间的键也就是数据库的键， 每个键都是一个字符串对象。
*   键空间的值也就是数据库的值， 每个值可以是字符串对象、 列表对象、 哈希表对象、 集
    合对象和有序集合对象中的任意一种Redis对象。  

>   因为数据库的键空间是一个字典， 所以所有针对数据库的操作， 比如添加一个键值对到
>   数据库， 或者从数据库中删除一个键值对， 又或者在数据库中获取某个键值对等， 实际上都
>   是通过对键空间字典进行操作来实现的  

#### 读写键空间时的维护操作

当使用Redis命令对数据库进行读写时， 服务器不仅会对键空间执行指定的读写操作， 还
会执行一些额外的维护操作， 其中包括：

*   在读取一个键之后（读操作和写操作都要对键进行读取） ， 服务器会根据键是否存在来
    更新服务器的键空间命中（hit） 次数或键空间不命中（miss） 次数， 这两个值可以在INFO
    stats命令的key space_hits属性和key space_misses属性中查看。  
*   在读取一个键之后， 服务器会更新键的LRU（最后一次使用） 时间， 这个值可以用于计
    算键的闲置时间， 使用OBJECT idletime命令可以查看键key的闲置时间  
*   如果服务器在读取一个键时发现该键已经过期， 那么服务器会先删除这个过期键， 然后
    才执行余下的其他操作  
*   如果有客户端使用WATCH命令监视了某个键， 那么服务器在对被监视的键进行修改之
    后， 会将这个键标记为脏（dirty） ， 从而让事务程序注意到这个键已经被修改过  
*   服务器每次修改一个键之后， 都会对脏（dirty） 键计数器的值增1， 这个计数器会触发
    服务器的持久化以及复制操作  
*   如果服务器开启了数据库通知功能， 那么在对键进行修改之后， 服务器将按配置发送相
    应的数据库通知 

### 设置键的生存时间或过期时间

通过EXPIRE命令或者PEXPIRE命令， 客户端可以以秒或者毫秒精度为数据库中的某个
键设置生存时间（Time To Live， TTL）/（PTTL) ， 在经过指定的秒数或者毫秒数之后， 服务器就会
自动删除生存时间为0的键  

#### 设置过期时间

四种方式：

*   EXPIRE<key><ttl>命令用于将键key的生存时间设置为ttl秒  
*   PEXPIRE<key><ttl>命令用于将键key的生存时间设置为ttl毫秒。  
*   EXPIREAT<key><timestamp>命令用于将键key的过期时间设置为timestamp所指定的
    秒数时间戳。  
*   PEXPIREAT<key><timestamp>命令用于将键key的过期时间设置为timestamp所指定的
    毫秒数时间戳。  

虽然有多种不同单位和不同形式的设置命令， 但实际上EXPIRE、 PEXPIRE、EXPIREAT三个命令都是使用**PEXPIREAT**命令来实现的： 无论客户端执行的是以上四个命令中的哪一个， 经过转换之后， 最终的执行效果都和执行PEXPIREAT命令一样。  

#### 保存过期时间

redisDb.expires字典保存了数据库所有键的过期时间，expires：过期字典

过期时间的键是一个指针，指向键空间的某个键对象，值是一个long long类型的整数（键的过期时间，一个毫秒精度的UNIX时间戳）

```c
typedef struct redisDb {
	//...
	//过期字典
    dict *expires;
}redisDb;
```

#### 移除过期时间

PERSIST命令就是PEXPIREAT命令的反操作： PERSIST命令在过期字典中查找给定的
键， 并解除键和值（过期时间） 在过期字典中的关联。  

#### 计算返回键剩余生存时间

TTL命令以秒为单位返回键的剩余生存时间， 而PTTL命令则以毫秒为单位返回键的剩余
生存时间

#### 过期键的判定

通过过期字典， 程序可以用以下步骤检查一个给定键是否过期：  

1.  检查给定键是否存在于过期字典： 如果存在， 那么取得键的过期时间。  
2.  检查当前UNIX时间戳是否大于键的过期时间： 如果是的话， 那么键已经过期； 否则
    的话， 键未过期。  

### 过期键删除策略

>   如果一个键过期了，那么它什么时候被删除呢

3种不同的删除策略

*   定时删除：在设置键的过期时间的同时， 创建一个定时器（timer） ， 让定时器在键的
    过期时间来临时， 立即执行对键的删除操作。  
*   惰性删除：放任键过期不管， 但是每次从键空间中获取键时， 都检查取得的键是否过
    期， 如果过期的话， 就删除该键； 如果没有过期， 就返回该键。  
*   定期删除：每隔一段时间， 程序就对数据库进行一次检查， 删除里面的过期键。 至于要
    删除多少过期键， 以及要检查多少个数据库， 则由算法决定  

#### 定时删除

优点：

*   通过使用定时器， 定时删除策略可以保证过期键会尽可能快地被删除， 并释放过期键所占用的内存。  

缺点：

*   它对CPU时间是最不友好的： 在过期键比较多的情况下， 删除过期键这一行为可能会占用相当一部分CPU时间， 在内存不紧张但是CPU时间非常紧张的情况下， 将CPU时间用在删除和当前任务无关的过期键上， 无疑会对服务器的响应时间和吞吐量造成影响。  
*   创建一个定时器需要用到Redis服务器中的时间事件， 而当前时间事件的实现方式——无序链表， 查找一个事件的时间复杂度为O（N） ——并不能高效地处理大量时间事件。  

#### 惰性删除

优点：

*   惰性删除策略对CPU时间来说是最友好的： 程序只会在取出键时才对键进行过期检查，这可以保证删除过期键的操作只会在非做不可的情况下进行， 并且删除的目标仅限于当前处理的键， 这个策略不会在删除其他无关的过期键上花费任何CPU时间。  

缺点：

*   它对内存是最不友好的： 如果一个键已经过期， 而这个键又仍然保留在数据库中， 那么只要这个过期键不被删除， 它所占用的内存就不会释放。 

#### 定期删除

>   定时和惰性的整合和折中

优点：

*   定期删除策略每隔一段时间执行一次删除过期键操作， 并通过限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响。  
*   通过定期删除过期键， 定期删除策略有效地减少了因为过期键而带来的内存浪费  

缺点：

*   难以确定删除操作执行的时长和频率

### Redis使用的过期键删除策略

>   Redis服务器实际使用的是惰性删除和定期删除两种策略： 通过配合使用这两种删除策略， 服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡  

###### 惰性删除策略的实现

过期键的惰性删除策略由db.c/expireIfNeeded函数实现， 所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查：  

*   如果输入键已经过期， 那么expireIfNeeded函数将输入键从数据库中删除。  
*   如果输入键未过期， 那么expireIfNeeded函数不做动作。  

###### 定期删除策略的实现

过期键的定期删除策略由redis.c/activeExpireCycle函数实现， 每当Redis的服务器周期性
操作redis.c/serverCron函数执行时， activeExpireCycle函数就会被调用， 它在规定的时间内，
分多次遍历服务器中的各个数据库， 从数据库的expires字典中随机检查一部分键的过期时
间， 并删除其中的过期键

工作流程

*   函数每次运行时， 都从一定数量的数据库中取出一定数量的随机键进行检查， 并删除其中的过期键  
*   全局变量current_db会记录当前activeExpireCycle函数检查的进度， 并在下一次activeExpireCy cle函数调用时， 接着上一次的进度进行处理。 比如说， 如果当前activeExpireCy cle函数在遍历10号数据库时返回了， 那么下次activeExpireCycle函数执行时， 将从11号数据库开始查找并删除过期键。  
*   随着activeExpireCycle函数的不断执行， 服务器中的所有数据库都会被检查一遍， 这时函数将current_db变量重置为0， 然后再次开始新一轮的检查工作。  

### AOF、 RDB和复制功能对过期键的处理 

#### 生成RDB文件

在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件时， 程序会对数据库中的键进行检查， 已过期的键不会被保存到新创建的RDB文件中。  

#### 载入RDB文件

*   如果服务器以主服务器模式运行， 那么在载入RDB文件时， 程序会对文件中保存的键进行检查， 未过期的键会被载入到数据库中， 而过期键则会被忽略， 所以过期键对载入RDB文件的主服务器不会造成影响。  
*   如果服务器以从服务器模式运行， 那么在载入RDB文件时， 文件中保存的所有键， 不论是否过期， 都会被载入到数据库中。 不过， 因为主从服务器在进行数据同步的时候， 从服务器的数据库就会被清空， 所以一般来讲， 过期键对载入RDB文件的从服务器也不会造成影响。 

#### AOF文件写入

当服务器以AOF持久化模式运行时， 如果数据库中的某个键已经过期， 但它还没有被惰性删除或者定期删除， 那么AOF文件不会因为这个过期键而产生任何影响。  

当过期键被惰性删除或者定期删除之后， 程序会向AOF文件追加（append） 一条DEL命令， 来显式地记录该键已被删除  

#### AOF重写

和生成RDB文件时类似， 在执行AOF重写的过程中， 程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的AOF文件中  

#### 复制

当服务器运行在复制模式下时， 从服务器的过期键删除动作由主服务器控制：  

*   主服务器在删除一个过期键之后， 会显式地向所有从服务器发送一个DEL命令， 告知从
    服务器删除这个过期键。  
*   从服务器在执行客户端发送的读命令时， 即使碰到过期键也不会将过期键删除， 而是继
    续像处理未过期的键一样来处理过期键  
*   从服务器只有在接到主服务器发来的DEL命令之后， 才会删除过期键  

通过由主服务器来控制从服务器统一地删除过期键， 可以保证主从服务器数据的一致性， 也正是因为这个原因， 当一个过期键仍然存在于主服务器的数据库时， 这个过期键在从服务器里的复制品也会继续存在。  

### 数据库通知

数据库通知是Redis 2.8版本新增加的功能， 这个功能可以让客户端通过订阅给定的频道或者模式， 来获知数据库中键的变化， 以及数据库中命令的执行情况。  

>   暂时略过

## RDB持久化

>   因为Redis是内存数据库， 它将自己的数据库状态储存在内存里面， 所以如果不想办法将储存在内存中的数据库状态保存到磁盘里面， 那么一旦服务器进程退出， 服务器中的数据库状态也会消失不见。  
>
>   为了解决这个问题， Redis提供了RDB持久化功能， 这个功能可以将Redis在内存中的数据库状态保存到磁盘里面， 避免数据意外丢失。  

*   RDB持久化既可以手动执行， 也可以根据服务器配置选项定期执行， 该功能可以将某个
    时间点上的数据库状态保存到一个RDB文件中  
*   RDB持久化功能所生成的RDB文件是一个经过压缩的二进制文件， 通过该文件可以还原
    生成RDB文件时的数据库状态  

#### RDB文件的创建和写入

>   有两个Redis命令可以用于生成RDB文件， 一个是SAVE， 另一个是BGSAVE。  

*   SAVE命令会阻塞Redis服务器进程， 直到RDB文件创建完毕为止， 在服务器进程阻塞期
    间， 服务器不能处理任何命令请求  
*   和SAVE命令直接阻塞服务器进程的做法不同， BGSAVE命令会派生出一个子进程， 然后
    由子进程负责创建RDB文件， 服务器进程（父进程） 继续处理命令请求  

创建RDB文件的实际工作由rdb.c/rdbSave函数完成， SAVE命令和BGSAVE命令会以不同的方式调用这个函数  

和使用SAVE命令或者BGSAVE命令创建RDB文件不同， RDB文件的载入工作是在服务器启动时自动执行的， 所以Redis并没有专门用于载入RDB文件的命令， 只要Redis服务器在启动时检测到RDB文件存在， 它就会自动载入RDB文件。  

tips：为AOF文件的更新频率通常比RDB文件的更新频率高， 所以：  

*   如果服务器开启了AOF持久化功能， 那么服务器会优先使用AOF文件来还原数据库状态。
*   只有在AOF持久化功能处于关闭状态时， 服务器才会使用RDB文件来还原数据库状态。   

##### SAVE命令执行时服务器的状态

>   当SAVE命令执行时， Redis服务器会被阻塞， 所以当SAVE命令正在执行时， 客户端发送的所有命令请求都会被拒绝。  

##### BGSAVE命令执行时的服务器状态  

因为BGSAVE命令的保存工作是由子进程执行的， 所以在子进程创建RDB文件的过程中， Redis服务器仍然可继续处理客户端的命令请求， 但是， 在BGSAVE命令执行期间， 服务器处理SAVE、 BGSAVE、 BGREWRITEAOF三个命令的方式会和平时有所不同  

*   首先， 在BGSAVE命令执行期间， 客户端发送的SAVE命令会被服务器拒绝， 服务器禁止SAVE命令BGSAVE命令同时执行是为了避免父进程（服务器进程） 和子进程同时执行两个rdbSave调用， 防止产生竞争条件。  
*   在BGSAVE命令执行期间， 客户端发送的BGSAVE命令会被服务器拒绝， 因为同时执行两个BGSAVE命令也会产生竞争条件。  
*   BGREWRITEAOF和BGSAVE两个命令不能同时执行：  
    *   如果BGSAVE命令正在执行， 那么客户端发送的BGREWRITEAOF命令会被延迟到BGSAVE命令执行完毕之后执行。  
    *   如果BGREWRITEAOF命令正在执行， 那么客户端发送的BGSAVE命令会被服务器拒绝  

##### RDB文件载入时的服务器状态  

服务器在载入RDB文件期间， 会一直处于阻塞状态， 直到载入工作完成为止。  

#### 自动间隔性保存

因为BGSAVE命令可以在不阻塞服务器进程的情况下执行， 所以Redis允许用户通过设置服务器配置的save选项， 让服务器每隔一段时间自动执行一次BGSAVE命令。用户可以通过save选项设置多个保存条件， 但只要其中任意一个条件被满足， 服务器就会执行BGSAVE命令。  

```conf
save 900 1
save 300 10
save 60 10000
```

##### 实现原理

当Redis服务器启动时， 用户可以通过指定配置文件或者传入启动参数的方式设置save选项， 如果用户没有主动设置save选项， 那么服务器会为save选项设置默认条件：  

通过用户配置或者默认配置设置redisServer.saveParams

```c
struct saveparam {
//秒数
time_t seconds;
//修改数
int changes;
};
```

redis.Server.dirty（计数器）+redisServer.lastSave

*   dirty计数器记录距离上一次成功执行SAVE命令或者BGSAVE命令之后， 服务器对数据库状态（服务器中的所有数据库） 进行了多少次修改（包括写入、 删除、 更新等操作） 。 
    *   当服务器成功执行一个数据库修改命令之后， 程序就会对dirty计数器进行更新： 命令修改了多少次数据库， dirty计数器的值就增加多少。   
*   lastsave属性是一个UNIX时间戳， 记录了服务器上一次成功执行SAVE命令或者BGSAVE命令的时间。  

Redis的服务器周期性操作函数serverCron默认每隔100毫秒就会执行一次， 该函数用于对正在运行的服务器进行维护， 它的其中一项工作就是检查save选项所设置的保存条件是否已经满足， 如果满足的话， 就执行BGSAV命令。  

*   程序会遍历并检查saveparams数组中的所有保存条件， 只要有任意一个条件被满足， 那么服务器就会执行BGSAVE命令  

    

#### RDB文件结构

*   REDIS：5字节， 保存着“REDIS”五个字符。通过这五个字符， 程序可以在载入文件时， 快速检查所载入的文件是否RDB文件。  
*   db_version：4字节，它的值是一个字符串表示的整数， 这个整数记录了RDB文件的版本号  
*   databases： 部分包含着零个或任意多个数据库， 以及各个数据库中的键值对数据 
    *   SELECTDB：1字节，当读入程序遇到这个值的时候， 它知道接下来要读入的将是一个数据库号码。
    *   db_number：数据库号码，读到时调用SELECT切换到对应的库
    *   key_value_pairs：数据库所有键值对数据  
*   EOF： 1字节，这个常量标志着RDB文件正文内容的结束， 当读入程序遇到这个值的时候， 它知道所有数据库的所有键值对都已经载入完毕了  
*   check_sum：8字节长的无符号整数，保存着一个校验和， 这个校验和是程序通过对REDIS、 db_version、 databases、 EOF四个部分的内容进行计算得出的。 服务器在载入RDB文件时， 会将载入数据所计算出的校验和与check_sum所记录的校验和进行对比， 以此来检查RDB文件是否有出错或者损坏的情况出现  

#### 分析RDB文件

od -c dump.rdb

使用od命令来分析Redis服务器产生的RDB文件， 该命令可以用给定的格式转存（dump） 并打印输入文件。 比如说， 给定-c参数可以以ASCII编码的方式打印输入文件， 给定-x参数可以以十六进制的方式打印输入文件  

>   Redis自带RDB文件检查工具redis-check-dump

## AOF持久化

>   除了RDB持久化功能之外， Redis还提供了AOF（Append Only File） 持久化功能。 与RDB持久化通过保存数据库中的键值对来记录数据库状态不同， AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的  

#### AOF持久化的实现

命令追加（append）+文件写入+文件同步

##### 命令追加

当AOF持久化功能处于打开状态时， 服务器在执行完一个写命令之后， 会以协议格式将被执行的写命令追加到服务器状态的redisServer.aof_buf缓冲区的末尾

##### 文件的写入和同步

Redis的服务器进程就是一个事件循环（loop） ， 这个循环中的文件事件负责接收客户端的命令请求， 以及向客户端发送命令回复，而时间事件则负责执行像serverCron函数这样需要定时运行的函数。

因为服务器在处理文件事件时可能会执行写命令， 使得一些内容被追加到aof_buf缓冲区里面， 所以在服务器每次结束一个事件循环之前， 它都会调用flushAppendOnlyFile函数， 考虑是否需要将aof_buf缓冲区中的内容写入和保存到AOF文件里面

 flushAppendOnlyFile函数的行为由服务器配置的appendfsync选项的值来决定

*   always：将aof_buf缓冲区中的所有内容写入并同步到AOF文件中
*   everysec（默认）：将aof_buf缓冲区中的所有内容写入到AOF文件中，如果上次同步AOF文件的时间距离现在超过一秒钟，那么再次对AOF文件进行同步，这个同步是有一个线程专门负责执行的
*   no：将aof_buf缓冲区中的所有内容写入到AOF文件，但并不对AOF文件进行同步，何时同步由操作系统决定

### AOF文件的载入和数据还原

>   因为AOF文件里面包含了重建数据库状态所需的所有写命令， 所以服务器只要读入并重新执行一遍AOF文件里面保存的写命令， 就可以还原服务器关闭之前的数据库状态。  

Redis读取AOF文件并还原数据库状态的详细步骤如下：  

*   创建一个不带网络连接的伪客户端（fake client） ： 因为Redis的命令只能在客户端上下文中执行， 而载入AOF文件时所使用的命令直接来源于AOF文件而不是网络连接， 所以服务器使用了一个没有网络连接的伪客户端来执行AOF文件保存的写命令， 伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样。  
*   从AOF文件中分析并读取出一条写命令。  
*   使用伪客户端执行被读出的写命令。  
*   一直执行步骤2和步骤3， 直到AOF文件中的所有写命令都被处理完毕为止。  

### AOF重写

>   因为AOF持久化是通过保存被执行的写命令来记录数据库状态的， 所以随着服务器运行时间的流逝， AOF文件中的内容会越来越多， 文件的体积也会越来越大， 如果不加以控制的话， 体积过大的AOF文件很可能对Redis服务器、 甚至整个宿主计算机造成影响， 并且AOF文件的体积越大， 使用AOF文件来进行数据还原所需的时间就越多。  

为了解决AOF文件体积膨胀的问题， Redis提供了AOF文件重写（rewrite） 功能。 通过该功能， Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件， 新旧两个AOF文件所保存的数据库状态相同， 但新AOF文件不会包含任何浪费空间的冗余命令， 所以新AOF文件的体积通常会比旧AOF文件的体积要小得多。

#### AOF文件重写的实现    

>   AOF文件重写并不需要对现有的AOF文件进行任何读取、 分析或者写入操作， 这个功能是通过读取服务器当前的数据库状态来实现的。  

首先从数据库中读取键现在的值， 然后用一条命令（最多64个）去记录键值对，代替之前记录这个键值对的多条命令， 这就是AOF重写功能的实现原理。  

#### AOF后台重写

BGREWRITEAOF命令的实现原理。

Redis将重写程序放到子进程里执行

问题：子进程进行重写时，数据库状态有变更

解决：加入了一个AOF重写缓冲区，将执行后的变更命令加入到缓冲区中，子进程完成AOF重写后，它它会向父进程发送一个信号， 父进程在接到该信号之后， 会调用一个信号处理函数：

*   将AOF重写缓冲区中的所有内容写入到新AOF文件中， 这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致。  
*   对新的AOF文件进行改名， 原子地（ atomic） 覆盖现有的AOF文件， 完成新旧两个AOF文件的替换  



## 事件

*   Redis服务器是一个事件驱动程序， 服务器需要处理以下两类事件：  
    *   文件事件（file event） ： Redis服务器通过套接字与客户端（或者其他Redis服务器） 进行连接， 而文件事件就是服务器对套接字操作的抽象。 服务器与客户端（或者其他服务器）的通信会产生相应的文件事件， 而服务器则通过监听并处理这些事件来完成一系列网络通信操作。  
        *   文件事件处理器是基于Reactor模式实现的网络通信程序。  
        *   文件事件是对套接字操作的抽象： 每次套接字变为可应答（acceptable） 、 可写（writable） 或者可读（readable） 时， 相应的文件事件就会产生。  
        *   文件事件分为AE_READABLE事件（读事件） 和AE_WRITABLE事件（写事件） 两类。  
    *   时间事件（time event） ： Redis服务器中的一些操作（比如serverCron函数） 需要在给定的时间点执行， 而时间事件就是服务器对这类定时操作的抽象。  
        *   时间事件分为定时事件和周期性事件： 定时事件只在指定的时间到达一次， 而周期性事
            件则每隔一段时间到达一次  
        *   服务器在一般情况下只执行serverCron函数一个时间事件， 并且这个事件是周期性事
            件  
*   文件事件和时间事件之间是合作关系， 服务器会轮流处理这两种事件， 并且处理事件的
    过程中也不会进行抢占  
*   时间事件的实际处理时间通常会比设定的到达时间晚一些。  

## 客户端

*   服务器状态结构使用clients链表连接起多个客户端状态， 新添加的客户端状态会被放到链表的末尾。
*   客户端状态的flags属性使用不同标志来表示客户端的角色， 以及客户端当前所处的状态。 
*   输入缓冲区记录了客户端发送的命令请求， 这个缓冲区的大小不能超过1GB。  
*   命令的参数和参数个数会被记录在客户端状态的argv和argc属性里面， 而cmd属性则记录了客户端要执行命令的实现函数。     
*   客户端有固定大小缓冲区和可变大小缓冲区两种缓冲区可用， 其中固定大小缓冲区的最大大小为16KB， 而可变大小缓冲区的最大大小不能超过服务器设置的硬性限制值。  
*   输出缓冲区限制值有两种， 如果输出缓冲区的大小超过了服务器设置的硬性限制， 那么客户端会被立即关闭； 除此之外， 如果客户端在一定时间内， 一直超过服务器设置的软性限制， 那么客户端也会被关闭。
*   当一个客户端通过网络连接连上服务器时， 服务器会为这个客户端创建相应的客户端状态。 网络连接关闭、 发送了不合协议格式的命令请求、 成为CLIENT KILL命令的目标、 空转时间超时、 输出缓冲区的大小超出限制， 以上这些原因都会造成客户端被关闭。    
*   处理Lua脚本的伪客户端在服务器初始化时创建， 这个客户端会一直存在， 直到服务器关闭  
*   处理Lua脚本的伪客户端在服务器初始化时创建， 这个客户端会一直存在， 直到服务器关闭  

## 服务器

>   Redis服务器负责与多个客户端建立网络连接， 处理客户端发送的命令请求， 在数据库中保存客户端执行命令所产生的数据， 并通过资源管理来维持服务器自身的运转  

*   一个命令请求从发送到完成主要包括以下步骤： 1） 客户端将命令请求发送给服务器；2） 服务器读取命令请求， 并分析出命令参数； 3） 命令执行器根据参数查找命令的实现函数， 然后执行实现函数并得出命令回复； 4） 服务器将命令回复返回给客户端。  
*   erverCron函数默认每隔100毫秒执行一次， 它的工作主要包括更新服务器状态信息，处理服务器接收的SIGTERM信号， 管理客户端资源和数据库状态， 检查并执行持久化操作等等  
*   服务器从启动到能够处理客户端的命令请求需要执行以下步骤： 1） 初始化服务器状态； 2） 载入服务器配置； 3） 初始化服务器数据结构； 4） 还原数据库状态； 5） 执行事件循环  

## 多机数据库

### 复制

>   在Redis中， 用户可以通过执行SLAVEOF命令或者设置slaveof选项， 让一个服务器去复制（replicate） 另一个服务器， 我们称呼被复制的服务器为主服务器（master） ， 而对主服务器进行复制的服务器则被称为从服务器（slave）   

#### 旧版复制功能的实现

2.8之前

Redis的复制功能分为同步（sync） 和命令传播（command propagate） 两个操作  

*   同步操作用于将从服务器的数据库状态更新至主服务器当前所处的数据库状态  
*   命令传播操作则用于在主服务器的数据库状态被修改， 导致主从服务器的数据库状态出现不一致时， 让主从服务器的数据库重新回到一致状态。  

#### 同步

>   当客户端向从服务器发送SLAVEOF命令， 要求从服务器复制主服务器时， 从服务器首先需要执行同步操作， 也即是， 将从服务器的数据库状态更新至主服务器当前所处的数据库状态。  

从服务器对主服务器的同步操作需要通过向主服务器发送SYNC命令来完成， 以下是SYNC命令的执行步骤：  

1.  从服务器向主服务器发送SYNC命令。  
2.  收到SYNC命令的主服务器执行BGSAVE命令， 在后台生成一个RDB文件， 并使用一个缓冲区记录从现在开始执行的所有写命令。  
3.  当主服务器的BGSAVE命令执行完毕时， 主服务器会将BGSAVE命令生成的RDB文件发送给从服务器， 从服务器接收并载入这个RDB文件， 将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。  
4.  主服务器将记录在缓冲区里面的所有写命令发送给从服务器， 从服务器执行这些写命令， 将自己的数据库状态更新至主服务器数据库当前所处的状态。  

#### 命令传播

>   在同步操作执行完毕之后， 主从服务器两者的数据库将达到一致状态， 但这种一致并不是一成不变的， 每当主服务器执行客户端发送的写命令时， 主服务器的数据库就有可能会被修改， 并导致主从服务器状态不再一致。  

>   为了让主从服务器再次回到一致状态， 主服务器需要对从服务器执行命令传播操作： 主服务器会将自己执行的写命令， 也即是造成主从服务器不一致的那条写命令， 发送给从服务器执行， 当从服务器执行了相同的写命令之后， 主从服务器将再次回到一致状态  

#### 旧版复制功能的缺陷

在Redis中， 从服务器对主服务器的复制可以分为以下两种情况 ：

*   初次复制： 从服务器以前没有复制过任何主服务器， 或者从服务器当前要复制的主服务器和上一次复制的主服务器不同  
*   断线后重复制： 处于命令传播阶段的主从服务器因为网络原因而中断了复制， 但从服务器通过自动重连接重新连上了主服务器， 并继续复制主服务器。  

tips：对于初次复制来说， 旧版复制功能能够很好地完成任务， 但对于断线后重复制来说， 旧
版复制功能虽然也能让主从服务器重新回到一致状态， 但效率却非常低。  

断线后重连，数据库状态不一致，重新同步sync，重写生成RDB文件，这个RDB文件有可能很多键值对是从数据库已有的，但是sync只能这样做，如果不一致的键值对很少，而需要重新生成的RDB很大，那这样就非常低效了

sync命令很耗资源

执行sync，主从服务器的执行流程：

1.  主服务器需要执行BGSAVE命令来生成RDB文件， 这个生成操作会耗费主服务器大量的CPU、 内存和磁盘I/O资源。  
2.  主服务器需要将自己生成的RDB文件发送给从服务器， 这个发送操作会耗费主从服务器大量的网络资源（带宽和流量） ， 并对主服务器响应命令请求的时间产生影响  
3.  接收到RDB文件的从服务器需要载入主服务器发来的RDB文件， 并且在载入期间， 从服务器会因为阻塞而没办法处理命令请求。  

#### 新版复制功能的实现

为了解决旧版复制功能在处理断线重复制情况时的低效问题， Redis从2.8版本开始， 使用PSYNC命令代替SYNC命令来执行复制时的同步操作。  

PSYNC有两种模式：

*   完整重同步
    *   其中完整重同步用于处理初次复制情况： 完整重同步的执行步骤和SYNC命令的执行步骤基本一样， 它们都是通过让主服务器创建并发送RDB文件， 以及向从服务器发送保存在缓冲区里面的写命令来进行同步。  
*   部分重同步
    *   而部分重同步则用于处理断线后重复制情况： 当从服务器在断线后重新连接主服务器时， 如果条件允许， 主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器， 从服务器只要接收并执行这些写命令， 就可以将数据库更新至主服务器当前所处的状态。  

##### 部分重同步的实现

部分重同步由三个部分组成：

*   主服务器的复制偏移量（replication offset） 和从服务器的复制偏移量。  
*   主服务器的复制积压缓冲区（replication backlog） 。  
*   服务器的运行ID（run ID） 。  

###### 复制偏移量

执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量：  

*   主服务器每次向从服务器传播N个字节的数据时， 就将自己的复制偏移量的值加上N。  
*   从服务器每次收到主服务器传播来的N个字节的数据时， 就将自己的复制偏移量的值加上N。

通过对比主从服务器的复制偏移量， 程序可以很容易地知道主从服务器是否处于一致状态

从服务器断线后重连到主服务器后，从服务器发送给PSYCN，报告自己的复制偏移量，这个时候应该怎么处理呢

###### 复制积压缓冲区

复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size） 先进先出（FIFO） 队列， 默认大小为1MB。  

主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令， 并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量  

当从服务器重新连上主服务器时， 从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器， 主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作：  

*   如果offset偏移量之后的数据（也即是偏移量offset+1开始的数据） 仍然存在于复制积压
    缓冲区里面， 那么主服务器将对从服务器执行部分重同步操作  
*   相反， 如果offset偏移量之后的数据已经不存在于复制积压缓冲区， 那么主服务器将对
    从服务器执行完整重同步操作。  

###### 服务器运行id

除了复制偏移量和复制积压缓冲区之外， 实现部分重同步还需要用到服务器运行ID（run ID） ：

格式：40个随机的十六进制字符组成

作用：当从服务器对主服务器进行初次复制时， 主服务器会将自己的运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来。  

当从服务器断线并重新连上一个主服务器时， 从服务器将向当前连接的主服务器发送之前保存的运行ID：  

*   如果从服务器保存的运行ID和当前连接的主服务器的运行ID相同， 那么说明从服务器
    断线之前复制的就是当前连接的这个主服务器， 主服务器可以继续尝试执行部分重同步操
    作。  
*   相反地， 如果从服务器保存的运行ID和当前连接的主服务器的运行ID并不相同， 那么
    说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器， 主服务器将对从服
    务器执行完整重同步操作。  

##### PSYNC命令的实现：

调用方式：

*   PSYNC ? -1     完整重同步
*   PSYNC <runid> <offset>

回复方式：

*   如果主服务器返回+FULLRESYNC <runid> <offset>回复， 那么表示主服务器将与从服
    务器执行完整重同步操作： 其中runid是这个主服务器的运行ID， 从服务器会将这个ID保存起
    来， 在下一次发送PSYNC命令时使用； 而offset则是主服务器当前的复制偏移量， 从服务器
    会将这个值作为自己的初始化偏移量。  
*   如果主服务器返回+CONTINUE回复， 那么表示主服务器将与从服务器执行部分重同步
    操作， 从服务器只要等着主服务器将自己缺少的那部分数据发送过来就可以了。  
*   如果主服务器返回-ERR回复， 那么表示主服务器的版本低于Redis 2.8， 它识别不了
    PSYNC命令， 从服务器将向主服务器发送SYNC命令， 并与主服务器执行完整同步操作。  

##### 心跳检测

在命令传播阶段， 从服务器默认会以每秒一次的频率， 向主服务器发送命令：  

`REPLCONF ACK <replication_offset>`

发送REPLCONF ACK命令对于主从服务器有三个作用：

*   检测主从服务器的网络连接状态。  
*   辅助实现min-slaves选项  
*   检测命令丢失。  

### 哨兵

>   由一个或多个Sentinel实例（instance） 组成的Sentinel系统（system） 可以监视任意多个主服务器， 以及这些主服务器属下的所有从服务器， 并在被监视的主服务器进入下线状态时， 自动将下线主服务器属下的某个从服务器升级为新的主服务器， 然后由新的主服务器代替已下线的主服务器继续处理命令请求

#### 启动并初始化哨兵

启动命令：

`redis-sentinel /path/to/your/sentinel.conf  `或`redis-server /path/to/your/sentinel.conf --sentinel  `

启动步骤：

1.  初始化服务器。  
2.  将普通Redis服务器使用的代码替换成Sentinel专用代码  
3.  初始化Sentinel状态。  
4.  根据给定的配置文件， 初始化Sentinel的监视主服务器列表  
5.  创建连向主服务器的网络连接。  

重点：

*   Sentinel只是一个运行在特殊模式下的Redis服务器， 它使用了和普通模式不同的命令
    表， 所以Sentinel模式能够使用的命令和普通Redis服务器能够使用的命令不同。  
*   Sentinel会读入用户指定的配置文件， 为每个要被监视的主服务器创建相应的实例结
    构， 并创建连向主服务器的命令连接和订阅连接， 其中命令连接用于向主服务器发送命令请
    求， 而订阅连接则用于接收指定频道的消息。  
*   Sentinel通过向主服务器发送INFO命令来获得主服务器属下所有从服务器的地址信息，
    并为这些从服务器创建相应的实例结构， 以及连向这些从服务器的命令连接和订阅连接。  
*   在一般情况下， Sentinel以每十秒一次的频率向被监视的主服务器和从服务器发送INFO
    命令， 当主服务器处于下线状态， 或者Sentinel正在对主服务器进行故障转移操作时，
    Sentinel向从服务器发送INFO命令的频率会改为每秒一次。  
*   对于监视同一个主服务器和从服务器的多个Sentinel来说， 它们会以每两秒一次的频
    率， 通过向被监视服务器的__sentinel__:hello频道发送消息来向其他Sentinel宣告自己的存
    在。  
*   每个Sentinel也会从__sentinel__:hello频道中接收其他Sentinel发来的信息， 并根据这些信
    息为其他Sentinel创建相应的实例结构， 以及命令连接。  
*   Sentinel只会与主服务器和从服务器创建命令连接和订阅连接， Sentinel与Sentinel之间则
    只创建命令连接。  
*   Sentinel以每秒一次的频率向实例（包括主服务器、 从服务器、 其他Sentinel） 发送PING
    命令， 并根据实例对PING命令的回复来判断实例是否在线， 当一个实例在指定的时长中连
    续向Sentinel发送无效回复时， Sentinel会将这个实例判断为主观下线。  
*   当Sentinel将一个主服务器判断为主观下线时， 它会向同样监视这个主服务器的其他
    Sentinel进行询问， 看它们是否同意这个主服务器已经进入主观下线状态。  
*   当Sentinel收集到足够多的主观下线投票之后， 它会将主服务器判断为客观下线， 并发
    起一次针对主服务器的故障转移操作。  

### 集群

>   Redis集群是Redis提供的分布式数据库方案， 集群通过分片（sharding） 来进行数据共享， 并提供复制和故障转移功能  

*   节点通过握手来将其他节点添加到自己所处的集群当中。  
*   集群中的16384个槽可以分别指派给集群中的各个节点， 每个节点都会记录哪些槽指派给了自己， 而哪些槽又被指派给了其他节点。  
*   节点在接到一个命令请求时， 会先检查这个命令请求要处理的键所在的槽是否由自己负责， 如果不是的话， 节点将向客户端返回一个MOVED错误， MOVED错误携带的信息可以指引客户端转向至正在负责相关槽的节点。  
*   对Redis集群的重新分片工作是由redis-trib负责执行的， 重新分片的关键是将属于某个槽的所有键值对从一个节点转移至另一个节点。  
*   如果节点A正在迁移槽i至节点B， 那么当节点A没能在自己的数据库中找到命令指定的数据库键时， 节点A会向客户端返回一个ASK错误， 指引客户端到节点B继续查找指定的数据库键  
*   MOVED错误表示槽的负责权已经从一个节点转移到了另一个节点， 而ASK错误只是两个节点在迁移槽的过程中使用的一种临时措施。  
*   集群里的从节点用于复制主节点， 并在主节点下线时， 代替主节点继续处理命令请求。  
*   集群中的节点通过发送和接收消息来进行通信， 常见的消息包括MEET、 PING、PONG、 PUBLISH、 FAIL五种。  

#### 节点

一个Redis集群通常由多个节点（node） 组成， 在刚开始的时候， 每个节点都是相互独立的， 它们都处于一个只包含自己的集群当中， 要组建一个真正可工作的集群， 我们必须将各个独立的节点连接起来， 构成一个包含多个节点的集群。  

连接各个节点的工作可以使用CLUSTER MEET命令来完成， 该命令的格式如下：  

`CLUSTER MEET <ip> <port>  `

##### 启动节点

Redis服务器在启动时会判断cluster-enable是否为yes来确定是否开启服务器的集群模式

节点启动后会继续使用单机模式下服务器的组件

集群相关的数据，节点将他们保存在cluster.h/clusterNode，cluster.h/clusterLink，cluster.h/clusterState

*   clusterNode：节点的当前状态，创建时间，名字，当前的配置纪元，IP地址和端口号等等
*   clusterLink：连接节点所需的有关信息，比如套接字描述符，输入缓冲区，输出缓冲区
*   clusterState：当前节点的视角下，集群的状态（上线、下线，集群节点个数，配置纪元）

CLUSTER MEET命令的实现：

`cluster meet bip bport`

收到命令的节点A将与节点B进行握手（handshake） ， 以此来确认彼此的存在， 并为将
来的进一步通信打好基础：  

1.  节点A会为节点B创建一个clusterNode结构， 并将该结构添加到自己的
    clusterState.nodes字典里面。  
2.  之后， 节点A将根据CLUSTER MEET命令给定的IP地址和端口号， 向节点B发送一条
    MEET消息（message） 。  
3.  如果一切顺利， 节点B将接收到节点A发送的MEET消息， 节点B会为节点A创建一个
    clusterNode结构， 并将该结构添加到自己的clusterState.nodes字典里面。  
4.  之后， 节点B将向节点A返回一条PONG消息。  
5.  如果一切顺利， 节点A将接收到节点B返回的PONG消息， 通过这条PONG消息节点A
    可以知道节点B已经成功地接收到了自己发送的MEET消息。  
6.  之后， 节点A将向节点B返回一条PING消息。  
7.  如果一切顺利， 节点B将接收到节点A返回的PING消息， 通过这条PING消息节点B
    可以知道节点A已经成功地接收到了自己返回的PONG消息， 握手完成。  

之后， 节点A会将节点B的信息通过Gossip协议传播给集群中的其他节点， 让其他节点也
与节点B进行握手， 最终， 经过一段时间之后， 节点B会被集群中的所有节点认识。

#### 槽指派  

Redis集群通过分片的方式来保存数据库中的键值对： 集群的整个数据库被分为16384个
槽（slot） ， 数据库中的每个键都属于这16384个槽的其中一个， 集群中的每个节点可以处理0
个或最多16384个槽。    

当数据库中的16384个槽都有节点在处理时， 集群处于上线状态（ok） ； 相反地， 如果数
据库中有任何一个槽没有得到处理， 那么集群处于下线状态（fail） 。  

通过向节点发送CLUSTER ADDSLOTS <slot> [slot ... ]设置节点

#### 在集群中执行命令

在对数据库中的16384个槽都进行了指派之后， 集群就会进入上线状态， 这时客户端就可以向集群中的节点发送数据命令了。
当客户端向节点发送与数据库键有关的命令时， 接收命令的节点会计算出命令要处理的数据库键属于哪个槽， 并检查这个槽是否指派给了自己：  

*   如果键所在的槽正好就指派给了当前节点， 那么节点直接执行这个命令  
*   如果键所在的槽并没有指派给当前节点， 那么节点会向客户端返回一个MOVED错误，指引客户端转向（redirect） 至正确的节点， 并再次发送之前想要执行的命令。  

##### 计算键属于哪个槽

算法：

```c
def slot_number(key):
	return CRC16(key) & 16383
```

其中CRC16（key） 语句用于计算键key的CRC-16校验和， 而&16383语句则用于计算出一个介于0至16383之间的整数作为键key的槽号。  

使用CLUSTER KEYSLOT<key>命令可以查看一个给定键属于哪个槽

MOVED错误

>   MOVED <slot> <ip>:<port>

集群模式的redis-cli客户端在接收到MOVED错误时， 并不会打印出MOVED错误，而是根据MOVED错误自动进行节点转向， 并打印出转向信息， 所以我们是看不见节点返回的MOVED错误的  

#### 重新分片

>   Redis集群的重新分片操作可以将任意数量已经指派给某个节点（源节点） 的槽改为指派给另一个节点（目标节点） ， 并且相关槽所属的键值对也会从源节点被移动到目标节点  

##### 原理

##### ASK问题



#### 复制与故障转移  

Redis集群中的节点分为主节点（master） 和从节点（slave） ， 其中主节点用于处理槽，而从节点则用于复制某个主节点， 并在被复制的主节点下线时， 代替下线主节点继续处理命令请求。  

当一个主节点下线后，其他队的几个主节点会从它的从节点中选择一个作为新的主节点，处理对应的槽，如果它再次上线，则作为新主节点的从节点

###### 故障检测

集群中的每个节点都会定期地向集群中的其他节点发送PING消息， 以此来检测对方是否在线， 如果接收PING消息的节点没有在规定的时间内， 向发送PING消息的节点返回PONG消息， 那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线（probable fail， PFAIL） 。    

集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息， 例如某个节点是处于在线状态、 疑似下线状态（PFAIL） ， 还是已下线状态（FAIL） 。  

如果在一个集群里面， 半数以上负责处理槽的主节点都将某个主节点x报告为疑似下线， 那么这个主节点x将被标记为已下线（FAIL） ， 将主节点x标记为已下线的节点会向集群广播一条关于主节点x的FAIL消息， 所有收到这条FAIL消息的节点都会立即将主节点x标记为已下线。  

###### 故障转移

>   当一个从节点发现自己正在复制的主节点进入了已下线状态时， 从节点将开始对下线主节点进行故障转移， 以下是故障转移的执行步骤：  

###### 选举新的主节点

#### 消息

>集群中的各个节点通过发送和接收消息（message） 来进行通信， 我们称发送消息的节
>点为发送者（sender） ， 接收消息的节点为接收者（receiver）   

*   MEET消息： 当发送者接到客户端发送的CLUSTER MEET命令时， 发送者会向接收者
    发送MEET消息， 请求接收者加入到发送者当前所处的集群里面。  
*   PING消息： 集群里的每个节点默认每隔一秒钟就会从已知节点列表中随机选出五个节
    点， 然后对这五个节点中最长时间没有发送过PING消息的节点发送PING消息， 以此来检测
    被选中的节点是否在线。 除此之外， 如果节点A最后一次收到节点B发送的PONG消息的时
    间， 距离当前时间已经超过了节点A的cluster-node-timeout选项设置时长的一半， 那么节点A
    也会向节点B发送PING消息， 这可以防止节点A因为长时间没有随机选中节点B作为PING消
    息的发送对象而导致对节点B的信息更新滞后  
*   PONG消息： 当接收者收到发送者发来的MEET消息或者PING消息时， 为了向发送者
    确认这条MEET消息或者PING消息已到达， 接收者会向发送者返回一条PONG消息。 另外，
    一个节点也可以通过向集群广播自己的PONG消息来让集群中的其他节点立即刷新关于这个
    节点的认识， 例如当一次故障转移操作成功执行之后， 新的主节点会向集群广播一条PONG
    消息， 以此来让集群中的其他节点立即知道这个节点已经变成了主节点， 并且接管了已下线
    节点负责的槽  
*   FAIL消息： 当一个主节点A判断另一个主节点B已经进入FAIL状态时， 节点A会向集群
    广播一条关于节点B的FAIL消息， 所有收到这条消息的节点都会立即将节点B标记为已下线。 
*   PUBLISH消息： 当节点接收到一个PUBLISH命令时， 节点会执行这个命令， 并向集群
    广播一条PUBLISH消息， 所有接收到这条PUBLISH消息的节点都会执行相同的PUBLISH命
    令  



# 个人理解

## 是什么

简单来说 Redis 就是一个使用 C 语言开发的数据库，不过与传统数据库不同的是Redis 的数据是存在内存中的 ，也就是它是内存数据库，所以读写速度非常快，因此 Redis 被广泛应用于缓存方向。

另外，Redis 除了做缓存之外，Redis 也经常用来做分布式锁，甚至是消息队列。

Redis 提供了多种数据类型来支持不同的业务场景。Redis 还支持事务 、持久化、Lua 脚本、多种集群方案。

### 技术选型

分布式缓存，使用的比较多的主要是 **Memcached** 和 **Redis**。

分布式缓存主要解决的是单机缓存的容量受服务器限制并且无法保存通用的信息。因为，本地缓存只在当前服务里有效，比如如果你部署了两个相同的服务，他们两者之间的缓存数据是无法共同的。

#### 对比：

**共同点** ：

1.  都是基于内存的数据库，一般都用来当做缓存使用。
2.  都有过期策略。
3.  两者的性能都非常高。

**区别** ：

1.  **Redis 支持更丰富的数据类型（支持更复杂的应用场景）**。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。
2.  **Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。**
3.  **Redis 有灾难恢复机制。** 因为可以把缓存中的数据持久化到磁盘上。
4.  **Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。**
5.  **Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.**
6.  **Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。** （Redis 6.0 引入了多线程 IO ）
7.  **Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。**
8.  **Memcached过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。**

### 缓存数据的处理流程

1.  如果用户请求的数据在缓存中就直接返回。
2.  缓存中不存在的话就看数据库中是否存在。
3.  数据库中存在的话就更新缓存中的数据。
4.  数据库中不存在的话就返回空数据。

### 为什么使用

使用缓存主要是为了提升用户体验以及应对更多的用户。

两个角度考虑

#### 高性能：

假如用户第一次访问数据库中的某些数据的话，这个过程是比较慢，毕竟是从硬盘中读取的。但是，如果说，用户访问的数据属于高频数据并且不会经常改变的话，那么我们就可以很放心地将该用户访问的数据存在缓存中。

那就是保证用户下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。

tips：注意双写一致性问题

#### 高并发：

一般像 MySQL 这类的数据库的 QPS 大概都在 1w 左右（4 核 8g） ，但是使用 Redis 缓存之后很容易达到 10w+，甚至最高能达到 30w+（就单机 redis 的情况，redis 集群的话会更高）。

直接操作缓存能够承受的数据库请求数量是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。进而，我们也就提高的系统整体的并发。



## 常见对象

### String

>   string 数据结构是简单的 key-value 类型。虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 简单动态字符串（simple dynamic string，**SDS**）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外,Redis 的 SDS API 是安全的，不会造成缓冲区溢出。

#### 常用命令

set,get,strlen,exists,dect,incr,setex

#### 适用场景：

*   常规key-value缓存应用
*   常规计数：验证码，微博数，粉丝数等
*   共享用户session
*   json序列化的对象

### hash

>   hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 hash 做了更多优化。另外，hash 是一个 string 类型的 field 和 value 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。 比如我们可以 hash 数据结构来存储用户信息，商品信息等等。

#### 常用命令：

hset,hmset,hexists,hget,hgetall,hkeys,hvals

#### 适用场景：

*   存储对象（用户信息，商品信息。。。）

### list

>链表是一种非常常见的数据结构，特点是易于数据元素的插入和删除并且且可以灵活调整链表长度，但是链表的随机访问困难。许多高级编程语言都内置了链表的实现比如 Java 中的 **LinkedList**，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 list 的实现为一个 双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

#### 常用命令

rpush,lpop,lpush,rpop,lrange,llen

#### 适用场景：

*   消息队列（rpush/lpop）
*   分页（lrange）

### set

>   set 类似于 Java 中的 `HashSet` 。Redis 中的 set 类型是一种无序集合，集合中的元素没有先后顺序。当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。

#### 常用命令

sadd,spop,smembers,sismember,scard,sinterstore,sunion

#### 适用场景：

*   非重集合
*   交并差集（共同好友）

### sortset

>   和 set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。

#### 常用命令：

zadd,zcard,zscore,zrange,zrevrange,zrem

#### 适用场景：

*    需要对数据根据某个权重进行排序的场景
*   排行榜

## key删除策略

Redis默认：定期删除+惰性删除

漏掉的keys：

#### 内存淘汰机制

Redis 提供 6 种数据淘汰策略：

1.  **volatile-lru（least recently used）**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
2.  **volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
3.  **volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
4.  **allkeys-lru（least recently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）
5.  **allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
6.  **no-eviction**：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。这个应该没人使用吧！

4.0 版本后增加以下两种：

1.  **volatile-lfu（least frequently used）**：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰
2.  **allkeys-lfu（least frequently used）**：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的 key

## 持久化方案

![](D:\my_files\desktop\yonghui\md\images\Redis持久化.jpg)

#### RDB

1、RDB方式，是将redis某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。

2、redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。

3、对于RDB方式，redis会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何IO操作的，这样就确保了redis极高的性能。

4、如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。

5、虽然RDB有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么RDB方式就不太适合你，因为即使你每5分钟都持久化一次，当redis故障时，仍然会有近5分钟的数据丢失。所以，redis还提供了另一种持久化方式，那就是AOF。

#### AOF

1、AOF，英文是Append Only File，即只允许追加不允许改写的文件。

2、如前面介绍的，AOF方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。

3、我们通过配置redis.conf中的appendonly yes就可以打开AOF功能。如果有写操作（如SET等），redis就会被追加到AOF文件的末尾。

4、默认的AOF持久化策略是每秒钟fsync一次（fsync是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis仍然可以保持很好的处理性能，即使redis故障，也只会丢失最近1秒钟的数据。

5如果在追加日志时，恰好遇到磁盘空间满、inode满或断电等情况导致日志写入不完整，也没有关系，redis提供了redis-check-aof工具，可以用来进行日志修复。

6、因为采用了追加方式，如果不做任何处理的话，AOF文件会变得越来越大，为此，redis提供了AOF文件重写（rewrite）机制，即当AOF文件的大小超过所设定的阈值时，redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了100次INCR指令，在AOF文件中就要存储100条指令，但这明显是很低效的，完全可以把这100条指令合并成一条SET指令，这就是重写机制的原理。

7、在进行AOF重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响AOF文件的可用性，这点大家可以放心。

8、AOF方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作redis时，不小心执行了FLUSHALL，导致redis内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要redis配置了AOF持久化方式，且AOF文件还没有被重写（rewrite），我们就可以用最快的速度暂停redis并编辑AOF文件，将最后一行的FLUSHALL命令删除，然后重启redis，就可以恢复redis的所有数据到FLUSHALL之前的状态了。是不是很神奇，这就是AOF持久化方式的好处之一。但是如果AOF文件已经被重写了，那就无法通过这种方法来恢复数据了。

9、虽然优点多多，但AOF方式也同样存在缺陷，比如在同样数据规模的情况下，AOF文件要比RDB文件的体积大。而且，AOF方式的恢复速度也要慢于RDB方式。

如果你直接执行BGREWRITEAOF命令，那么redis会生成一个全新的AOF文件，其中便包括了可以恢复现有数据的最少的命令集。

10、如果运气比较差，AOF文件出现了被写坏的情况，redis并不会贸然加载这个有问题的AOF文件，而是报错退出。这时可以通过以下步骤来修复出错的文件：

1.备份被写坏的AOF文件
2.运行redis-check-aof –fix进行修复
3.用diff -u来看下两个文件的差异，确认问题点
4.重启redis，加载修复后的AOF文件

##### AOF重写

1、在重写即将开始之际，redis会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。

2、与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中，这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。

3、当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中。

4、当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中了。

#### 区别

*   RDB需要定时持久化，风险是可能会丢两次持久之间的数据，量可能很大。
*   AOF每秒fsync一次指令硬盘，如果硬盘IO慢，会阻塞父进程；风险是会丢失1秒多的数据；在Rewrite过程中，主进程把指令存到mem-buffer中，最后写盘时会阻塞主进程。

## 双写一致性

##### 理解

>   如果仅仅查询的话，缓存的数据和数据库的数据是没问题的。但是，当我们要**更新**时候，各种情况很可能就造成数据库和缓存的数据不一致

理论上说，设置好键的过期时间，大多数情况下就可以保证db和Redis中的数据是一致的，只要缓存中的数据过期了，随后读的时候，走缓存没找到，走数据库，然后再把数据写入缓存

除了设置过期时间，还需要更多的措施来尽可能保证双写一致性

##### 更新

两种选择

*   先更新db，再更新Redis
*   先更新Redis，再更新db

两个都需要保证这两个操作同时成功或者同时失败，这样就会演变成一个分布式事务问题

如果原子性被破坏，可能导致以下两种情况

*   更新db成功了，更新Redis失败了
*   更新Redis成功了，更新db失败了

分析：

###### 更新Redis

两种方案

*   更新
*   删除

>   一般采用删除策略

原因：

*   并发环境下，无论是先操作数据库还是后操作数据库而言，如果加上更新缓存，那就更加容易导致数据库与缓存数据不一致问题
*   如果每次更新了数据库，都要更新缓存（这里指的是频繁更新的场景，这会耗费一定的性能），不如直接删除掉。等再次读取时，缓存里没有，那我到数据库找，在数据库找到再写到缓存里边(**懒加载**)

###### 先更新db，再删除Redis

正常情况：

*   先更新db，OK
*   在更新Redis，OK

原子性被破坏时：

*   第一步更新db（成功），第二步更新Redis（失败），这样子db里对的是新数据，Redis中是旧数据
*   第一步更新db（失败），直接返回错误信息，这样不会出现数据不一致

删除缓存失败的解决方案：

*   把要删的key发送到消息队列中
*   自己去消费消息，获得需要删除的key
*   不断重试删除操作，直到成功

并发场景下的问题（概率很低）：

*   缓存刚好失效
*   线程A查询数据库，得一个旧值
*   线程B将新值写入数据库
*   线程B删除缓存
*   线程A将查到的旧值写入缓存

解决思路：

-   将需要删除的key发送到消息队列中
-   自己消费消息，获得需要删除的key
-   不断重试删除操作，直到成功

###### 先删除Redis，再更新db

正常情况：

*   删除缓存，OK
*   更新db，OK

原子性被破坏的情况：

*   第一步删除缓存（成功），第二次更新db（失败），数据库和缓存数据一致
*   第一步删除缓存（失败），直接返回错误信息，数据库和缓存的数据还是一致的

并发场景下的问题：

-   线程A删除了缓存
-   线程B查询，发现缓存已不存在
-   线程B去数据库查询得到旧值
-   线程B将旧值写入缓存
-   线程A将新值写入数据库

解决思路：

*   将删除缓存、修改数据库、读取缓存等的操作积压到**队列**里边，实现**串行化**。

###### 对比两种方案

各有优劣

-   先删除Redis，再更新db

-   -   在高并发下表现不如意，在原子性被破坏时表现优异

-   先更新db，再删除Redis

-   -   在高并发下表现优异，在原子性被破坏时表现不如意

## 缓存击穿&穿透&雪崩

#### 缓存穿透

##### 理解

*   缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，我们数据库的 id 都是1开始自增上去的，如发起为id值为 -1 的数据或 id 为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大，严重会把数据库挂掉
*   如果不对参数做校验，数据库id都是大于0的，我一直用小于0的参数去请求你，每次都能绕开Redis直接打到数据库，数据库也查不到，每次都这样，并发量就上去了

##### 解决

*   接口层做校验，比如用户鉴权校验，参数效验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。
*   从缓存取不到的数据，在数据库中也没有取到，这时也可以将对应Key的Value对写为null、位置错误、稍后重试这样的值，或者看具体的场景，缓存有效时间可以设置短点，如30秒
*   布隆过滤器
    *   原理就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。
    *   一个元素进来
        *   使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。
        *   根据得到的哈希值，在位数组中把对应下标的值置为 1。
    *   判断一个元素是否存在
        *   对给定元素再次进行相同的哈希计算；
        *   得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。
*   网关层Nginx也应该有配置项，可以让运维同学对单个IP每秒访问次数超出阈值的IP都拉黑。



#### 缓存雪崩

##### 理解

同一时间热点key大面积失效（key同时过期/缓存挂掉），那一瞬间Redis跟没有一样，大数量级别的请求直接打到数据库，瞬间把数据挂掉

##### 解决

*   事前
    *   批量网Redis中存数据时，设置过期时间时加上随机值，避免同一时间大面积key同时失效
    *   使用集群缓存，保证高可用
    *   设置热点数据永不过期
*   事中
    *   Hystrix进行限流 & 降级，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。以此来保护最后的 MySQL 不会被大量的请求给打死。
*   事后
    *   Redis持久化，恢复挂掉的缓存

#### 缓存击穿

##### 理解

这个跟缓存雪崩有点像，但是又有一点不一样，缓存雪崩是因为大面积的缓存失效，打崩了DB，而缓存击穿不同的是缓存击穿是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。

##### 解决

*   设置热点数据永不过期
*   加上互斥锁（mutex key）
    *   使用setnx实现锁的效果

```java
public String get(key) {
      String value = redis.get(key);
      if (value == null) { 
          //代表缓存值过期
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
          if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  
              //代表设置成功
              value = db.get(key);
              redis.set(key, value, expire_secs);
              redis.del(key_mutex);
          } else {  
              //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
              sleep(50);
              get(key);  //重试
          }
      } else {
          return value;      
      }
 }
```

## 分布式锁

#### 理解

分布式锁本质上要实现的目标就是在 Redis 里面占一个“坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。

占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑，先来先占， 用完了，再调用 del 指令释放茅坑。

```shell
setnx key1
expire key1
del key1
```

`原子性无法解决`

比如：setnx设置成功，expire的时候失败了，咋整？

当时出现了很多第三方插件处理此类问题，但是比较混乱，Redis2.8版本坐着加入了set指令的扩展参数

```lua
set key1 ture ex 5 nx
del key1
```

原子性问题解决，但是超时问题，可冲入问题等等无法解决，第三方插件通过lua脚本解决

比如删除的时候，去校验是否当前线程锁定的，就把比较和删除这样一些动作都放到一起

```lua
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```

## 消息队列

对于只有一组消费者，且对消息的可靠性没有过多的要求时，可以使用Redis做一个简单的消息队列

![](D:\my_files\desktop\yonghui\md\images\Redis实现简单消息队列.jpg)

但是当队列为空时，lpop和rpop会一直空轮训，消耗资源；所以引入阻塞读blpop和brpop（b代表blocking），阻塞读在队列没有数据的时候进入休眠状态，一旦数据到来则立刻醒过来，消息延迟几乎为零

注意：如果线程一直阻塞在那里，Redis客户端的连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用，这个时候blpop和brpop或抛出异常，所以在编写客户端消费者的时候要小心，如果捕获到异常，还有重试。















